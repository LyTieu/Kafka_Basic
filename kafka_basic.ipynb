{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n",
      "Produced event to topic purchase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "from random import choice\n",
    "\n",
    "producer = Producer({'bootstrap.servers': 'localhost:9092'})\n",
    "\n",
    "#build delivery callback\n",
    "def delivery_callback(err, msg):\n",
    "    if err:\n",
    "        print(\"Error occured: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced event to topic {topic}\".format(topic = msg.topic()))\n",
    "\n",
    "topic = \"purchase\"\n",
    "user_names = ['T', 'Jame', 'Smith']\n",
    "products = ['Food', 'Suit', 'Bike', 'Phone']\n",
    "\n",
    "for _ in range(10):\n",
    "    user_name = choice(user_names)\n",
    "    product = choice(products)\n",
    "    producer.produce(topic, product, user_name, callback = delivery_callback)\n",
    "\n",
    "producer.poll(1000)\n",
    "producer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting... \n",
      "Waiting... \n",
      "Waiting... \n",
      "Consumed event from topic purchase: key = Smith value = Bike\n",
      "Consumed event from topic purchase: key = Jame value = Food\n",
      "Consumed event from topic purchase: key = Jame value = Food\n",
      "Consumed event from topic purchase: key = T value = Suit\n",
      "Consumed event from topic purchase: key = T value = Phone\n",
      "Consumed event from topic purchase: key = T value = Food\n",
      "Consumed event from topic purchase: key = Jame value = Phone\n",
      "Consumed event from topic purchase: key = T value = Bike\n",
      "Consumed event from topic purchase: key = Smith value = Bike\n",
      "Consumed event from topic purchase: key = Jame value = Suit\n",
      "Waiting... \n",
      "Waiting... \n",
      "Waiting... \n",
      "Waiting... \n",
      "Waiting... \n",
      "Waiting... \n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "consumer = Consumer({\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'product_group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "})\n",
    "\n",
    "consumer.subscribe(['purchase'])\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            print(\"Waiting... \")\n",
    "        \n",
    "        elif msg.error():\n",
    "            print(\"Error occured: {}\".format(msg.error()))\n",
    "        else:\n",
    "            print(\"Consumed event from topic {topic}: key = {key} value = {value}\" \\\n",
    "                    .format(topic = msg.topic(), key = msg.key().decode('utf-8'), value = msg.value().decode('utf-8')))\n",
    "except KeyboardInterrupt:\n",
    "        pass\n",
    "finally:\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Test\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"value\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.readStream \\\n",
    "          .format(\"csv\") \\\n",
    "          .schema(schema) \\\n",
    "          .load(\"test.csv\")\n",
    "\n",
    "# query = df.writeStream \\\n",
    "#           .outputMode(\"append\") \\\n",
    "#           .format(\"console\") \\\n",
    "#           .start()\n",
    "\n",
    "#query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
